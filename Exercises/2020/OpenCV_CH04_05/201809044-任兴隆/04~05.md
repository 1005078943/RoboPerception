##第四章
###4.1 Mat结构的使用
自2001年以来，OpenCV的函数库一直是基于C接口构建的，因此在最初的几个OpenCV版本中，一般使用名为Ipllmage的C语言结构体在内存中存储图像。
对于OpenCV1.X时代的基于C语言接口而建的图像存储格式Ipllmage ，如果在退出前忘记release掉的话，就会照成内存泄露，而且用起来有些不便，我们在调试的时候，往往要花费很多时间在手动释放内存的问题上。虽然对于小型的程序来说，手动管理内存不是问题，但一旦需要书写和维护的代码越来越庞大。
从OpenCV踏入2.0时代，使用Mat类数据结构作为主打之后，OpenCV变得越发像需要很少编程涵养的 Matlab那样，上手很方便。甚至有些函数名称都和Matlab一样，比如大家所熟知的imread、imwrite、imshow等函数。
关于Mat类，首先我们要知道的是：
(1)不必再手动为其开辟空间。
(2)不必再在不需要时立即将空间释放。
这里指的是手动开辟空间并非必须，但它依旧是存在的——大多数OpenCV函数仍会手动地为输出数据开辟空间。当传递一个已经存在的Mat对象时，开辟好的矩阵空间会被重用。也就是说，我们每次都使用大小正好的内存来完成任务。
总而言之，Mat是一个类，由两个数据部分组成：矩阵头(包含矩阵尺寸、存储方法、存储地址等信息)和一个指向存储所有像素值的矩阵(根据所选存储方法的不同，矩阵可以是不同的维数)的指针。矩阵头的尺寸是常数值，但矩阵本身的尺寸会依图像的不同而不同，通常比矩阵头的尺寸大数个数量级。因此，当在程序中传递图像并创建副本时，大的开销是由矩阵造成的，而不是信息头。OpenCV是一个图像处理库，囊括了大量的图像处理函数，为了解决问题通常要使用库中的多个函数，因此在函数中传递图像是常有的事。同时不要忘了我们正在讨论的是计算量很大的图像处理算法，因此，除非万不得已，不应该进行大图像的复制，因为这会降低程序的运行速度。
为了解决此问题，OpenCV使用了引用计数机制。其思路是让每个Mat对象有自己的信息头，但共享同一个矩阵。这通过让矩阵指针指向同一地址而实现。而拷贝构造函数则只复制信息头和矩阵指针，而不复制矩阵。
如下代码
 #include <iostream>
 #include <opencv2/opencv.hpp>
using namespace std;
using namespace cv;

int main()
{
    Mat M1(3,3,CV_8UC3,Scalar(0, 0, 255));
    cout << "M1 = " << endl << " "  << M1 << endl;

    Mat M2(Size(3, 2), CV_8UC3, Scalar(1,2,3));
    cout << "M2 = " << endl << " " << M2 << endl;

    Mat M3(M2);
    cout << "M3 = " << endl << " " << M3 << endl;

    Mat M4(M2, Range(1,2), Range(1,2));
    cout << "M4 = " << endl << " " << M4 << endl;

    waitKey(0);
    return 0;
}
运行结果如下
![13.png](https://i.loli.net/2020/11/25/QuKcJtdZnamqSlB.png)

###4.2像素值的存储方法
存储像素值需要指定颜色空间和数据类型。其中，颜色空间是指针对一个给定的颜色，如何组合颜色元素以对其编码。最简单的颜色空间要属灰度级空间，只处理黑色和白色，对它们进行组合便可以产生不同程度的灰色。
对于彩色方式则有更多种类的颜色空间，但不论哪种方式都是把颜色分成三个或者四个基元素，通过组合基元素可以产生所有的颜色。RGB 颜色空间是最常用的一种颜色空间，这归功于它也是人眼内部构成颜色的方式。它的基色是红色、绿色和蓝色，有时为了表示透明颜色也会加入第四个元素alpha (A)。
颜色系统有很多，它们各有优势，具体如下。
·RGB是最常见的，这是因为人眼采用相似的工作机制，它也被显示设备所采用
· HSV和HLS把颜色分解成色调、饱和度和亮度/明度。这是描述颜色更自然的方式，比如可以通过抛弃最后一个元素，使算法对输入图像的光照条件不敏感
YCrCb在JPEG 图像格式中广泛使用CIEL*a*b*是一种在感知上均匀的颜色空间，它适合用来度量两个颜色之间的距离。每个组成元素都有其自己的定义域，而定义域取决于其数据类型，如何存储一个元素决定了我们在其定义域上能够控制的精度。最小的数据类型是char，占一个字节或者8位，可以是有符号型(0到255之间)或无符号型(-127到+127之间)。尽管使用三个char型元素已经可以表示1600万种可能的颜色(使用RGB颜色空间)，但若使用float(4字节，32位)或double(8字节，64位)则能给出更加精细的颜色分辨能力。但增加元素的尺寸也会增加图像所占的内存空间。

###4.3常用的数据结构和函数
(1) 点的表示：Point类
Point类数据结构表示了二维坐标系下的点，即由其图像坐标x和y指定的2D点。用法如下：
Point point;
point.x=10;
point.y =8;
或者
Point point = Point (10, B)；
另外，在OpenCV中有如下定义：
typedef Point_<int> Point2i;
typedef Point2i Point;
typedef Point_<float> Point2f;
所以，Point <int、Point2i、Point互相等价，Point_<float>、Point2f互相等价。
(2) 颜色的表示：Scalar类
Scalar()表示具有4个元素的数组，在OpenCV中被大量用于传递像素值，如RGB颜色值。而RGB颜色值为三个参数，其实对于Scalar函数来说，如果用不到第四个参数，则不需要写出来；若只写三个参数，OpenCV会认为我们就想表示三个参数。
来看个例子。如果给出以下颜色参数表达式：
Scalar( a, b, c)
那么定义的RGB颜色值：红色分量为c，绿色分量为b，蓝色分量为a。Scalar类的源头为Scalar_类，而Scalar_类是 Vec4x的一个变种，我们常用的Scalar 其实就是 Scalar_<double>。这就解释了为什么很多函数的参数输入可以是Mat,也可以是Scalar。
(3) 尺寸的表示：Size类
通过在代码中对Size 类进行“转到定义”操作，我们可以在路径下，找到Size类相关的源代码：
typedef Size_<int> Size2i;
typedef Size2i Size;
其中，Size_ 是个模板类，在这里Size_<int>表示其类体内部的模板所代表的类型为 int。那这两句代码的意思，就是首先给已知的数据类型Size_<int>起个新名字，叫Size2i。然后又给已知的数据类型Size2i起个新名字，叫Size。所以，连起来就是，Size_<int>、Size2i、Size这三个类型名等价。

###4.4 矩形的表示：Rect类
Rect类的成员变量有x、y、width、height，分别为左上角点的坐标和矩形的宽和高。常用的成员函数有：Size()返回值为 Size; area()返回矩形的面积；contains(Point)判断点是否在矩形内；inside(Rect)函数判断矩形是否在该矩形内；t1()返回左上角点坐标；br()返回右下角点坐标。值得注意的是，如果想求两个矩形的交集和并集，可以用如下格式：
Rect rect = rectl & rect2;
Rect rect = rectl I rect2;
如果想让矩形进行平移操作和缩放操作，甚至可以这样写：
Rect rectShift = rect + point;

###4.5 基本图形绘制的实验
代码如下
 #include <opencv2/opencv.hpp>

using namespace cv;

 #define WINDOW_NAME1 "【绘制图1】"        //为窗口标题定义的宏
 #define WINDOW_NAME2 "【绘制图2】"        //为窗口标题定义的宏
 #define WINDOW_WIDTH 600                 //定义窗口大小的宏  

void DrawEllipse(Mat img, double angle);//绘制椭圆
void DrawFilledCircle(Mat img, Point center);//绘制圆
void DrawPolygon(Mat img);//绘制多边形
void DrawLine(Mat img, Point start, Point end);//绘制线段

int main(int argc, char *argv[])
{
    //QCoreApplication  a(argc, argv);
    // 创建空白的Mat图像
    Mat atomImage = Mat::zeros(WINDOW_WIDTH, WINDOW_WIDTH, CV_8UC3);
    Mat rookImage = Mat::zeros(WINDOW_WIDTH, WINDOW_WIDTH, CV_8UC3);

    //一、绘制化学中的原子示例图
    // 1、先绘制出椭圆
    DrawEllipse(atomImage, 90);
    DrawEllipse(atomImage, 0);
    DrawEllipse(atomImage, 45);
    DrawEllipse(atomImage, -45);

    // 2、再绘制圆心
    DrawFilledCircle(atomImage, Point(WINDOW_WIDTH / 2, WINDOW_WIDTH / 2));

    //二、绘制组合图
    //1、先绘制出椭圆
    DrawPolygon(rookImage);

    //2、绘制矩形
    rectangle(rookImage,
        Point(0, 7 * WINDOW_WIDTH / 8),
        Point(WINDOW_WIDTH, WINDOW_WIDTH),
        Scalar(0, 255, 255),
        -1,
        8);

    //3、绘制一些线段
    DrawLine(rookImage, Point(0, 15 * WINDOW_WIDTH / 16), Point(WINDOW_WIDTH, 15 * WINDOW_WIDTH / 16));
    DrawLine(rookImage, Point(WINDOW_WIDTH / 4, 7 * WINDOW_WIDTH / 8), Point(WINDOW_WIDTH / 4, WINDOW_WIDTH));
    DrawLine(rookImage, Point(WINDOW_WIDTH / 2, 7 * WINDOW_WIDTH / 8), Point(WINDOW_WIDTH / 2, WINDOW_WIDTH));
    DrawLine(rookImage, Point(3 * WINDOW_WIDTH / 4, 7 * WINDOW_WIDTH / 8), Point(3 * WINDOW_WIDTH / 4, WINDOW_WIDTH));

    //三、显示绘制出的图像
    imshow(WINDOW_NAME1, atomImage);
    moveWindow(WINDOW_NAME1, 0, 200);
    imshow(WINDOW_NAME2, rookImage);
    moveWindow(WINDOW_NAME2, WINDOW_WIDTH, 200);

    waitKey(0);
}

void DrawEllipse(Mat img, double angle)
{
    int thickness = 2;
    int lineType = 8;

    ellipse(img,
        Point(WINDOW_WIDTH / 2, WINDOW_WIDTH / 2), // 椭圆中心
        Size(WINDOW_WIDTH / 4, WINDOW_WIDTH / 16), // 外切矩形
        angle, // 椭圆旋转角度
        0,
        360,
        Scalar(255, 129, 0), // 蓝色
        thickness, // 线宽
        lineType); // 线性 （连通性）
}

void DrawFilledCircle(Mat img, Point center)
{
    int thickness = -1;
    int lineType = 8;

    circle(img,
        center,
        WINDOW_WIDTH / 32,
        Scalar(0, 0, 255),
        thickness,
        lineType);
}

void DrawPolygon(Mat img)
{
    int lineType = 8;

    //创建一些点
    Point rookPoints[1][20];
    rookPoints[0][0] = Point(WINDOW_WIDTH / 4, 7 * WINDOW_WIDTH / 8);
    rookPoints[0][1] = Point(3 * WINDOW_WIDTH / 4, 7 * WINDOW_WIDTH / 8);
    rookPoints[0][2] = Point(3 * WINDOW_WIDTH / 4, 13 * WINDOW_WIDTH / 16);
    rookPoints[0][3] = Point(11 * WINDOW_WIDTH / 16, 13 * WINDOW_WIDTH / 16);
    rookPoints[0][4] = Point(19 * WINDOW_WIDTH / 32, 3 * WINDOW_WIDTH / 8);
    rookPoints[0][5] = Point(3 * WINDOW_WIDTH / 4, 3 * WINDOW_WIDTH / 8);
    rookPoints[0][6] = Point(3 * WINDOW_WIDTH / 4, WINDOW_WIDTH / 8);
    rookPoints[0][7] = Point(26 * WINDOW_WIDTH / 40, WINDOW_WIDTH / 8);
    rookPoints[0][8] = Point(26 * WINDOW_WIDTH / 40, WINDOW_WIDTH / 4);
    rookPoints[0][9] = Point(22 * WINDOW_WIDTH / 40, WINDOW_WIDTH / 4);
    rookPoints[0][10] = Point(22 * WINDOW_WIDTH / 40, WINDOW_WIDTH / 8);
    rookPoints[0][11] = Point(18 * WINDOW_WIDTH / 40, WINDOW_WIDTH / 8);
    rookPoints[0][12] = Point(18 * WINDOW_WIDTH / 40, WINDOW_WIDTH / 4);
    rookPoints[0][13] = Point(14 * WINDOW_WIDTH / 40, WINDOW_WIDTH / 4);
    rookPoints[0][14] = Point(14 * WINDOW_WIDTH / 40, WINDOW_WIDTH / 8);
    rookPoints[0][15] = Point(WINDOW_WIDTH / 4, WINDOW_WIDTH / 8);
    rookPoints[0][16] = Point(WINDOW_WIDTH / 4, 3 * WINDOW_WIDTH / 8);
    rookPoints[0][17] = Point(13 * WINDOW_WIDTH / 32, 3 * WINDOW_WIDTH / 8);
    rookPoints[0][18] = Point(5 * WINDOW_WIDTH / 16, 13 * WINDOW_WIDTH / 16);
    rookPoints[0][19] = Point(WINDOW_WIDTH / 4, 13 * WINDOW_WIDTH / 16);

    const Point* ppt[1] = { rookPoints[0] }; // 一个元素的 point 指针数组：每个元素表示指向一个point结构类型的存储地址
    //const Point** ppt = &(rookPoints[0]);
    //int npt[] = { 20 };
    int ival = 20;
    int* npt = &ival;

    fillPoly(img,
        &ppt[0], // 多边形顶点集合
        npt, // 多边形顶点数目 
        1,
        Scalar(255, 255, 255),
        lineType);
}

void DrawLine(Mat img, Point start, Point end)
{
    int thickness = 2;
    int lineType = 8;
    line(img,
        start, // 起始点
        end, // 终止点
        Scalar(0, 0, 0),
        thickness,
        lineType);
}
代码运行如图
![14.png](https://i.loli.net/2020/11/25/5NJPOwKYb9dh2Sg.png)

##第五章
###5.1
图像矩阵的大小取决于所用的颜色模型，确切地说取决于所用通道数，而对于多通道图像来说，矩阵中的列会包含多个子列，其子列个数与通道数相等
###5.2颜色空间缩减
我们知道，若矩阵元素存储的是单通道像素，使用C或C++的无符号字符类型，那么像素可有256个不同值。但若是三通道图像，这种存储格式的颜色数就太多了(确切地说，有一千六百多万种)。用如此之多的颜色来进行处理，可能会对我们的算法性能造成严重影响。
其实，仅用这些颜色中具有代表性的很小的部分，就足以达到同样的效果。如此，颜色空间缩减(colorspacereduction)便可以派上用场了，它在很多应用中可以大大降低运算复杂度。颜色空间缩减的做法是：将现有颜色空间值除以某个输入值，以获得较少的颜色数。也就是"做减法”，比如颜色值0到9可取为新值0，10到19可取为10，以此类推。如uchar类型的三通道图像，每个通道取值可以是0～255，于是就有256×256个不同的值。

###5.3计时函数
另外有个问题是如何计时。可以利用这两个简便的计时函数 getTickCount)和 getTickFrequency()-getTickCount()函数返回CPU自某个事件(如启动电脑)以来走过的时钟周期数getTickFrequency()函数返回CPU一秒钟所走的时钟周期数。这样，我们就能轻松地以秒为单位对某运算计时。

###5.4访问图像中像素的三类方法
任何图像处理算法，都是从操作每个像素开始的。即使我们不会使用OpenCV提供的各种图像处理函数，只要了解了图像处理算法的基本原理，也可以写出具有相同功能的程序。在OpenCV中，提供了三种访问每个像素的方法。
·方法一 指针访问：C操作符[]：
方法二迭代器 iterator;
方法三动态地址计算。
这三种方法在访问速度上略有差异。debug模式下，这种差异非常明显，不过在release模式下，这种差异就不太明显了。我们通过一组程序来说明这几种方法。程序的目的是减少图像中颜色的数量，比如原来的图像是是256种颜色，我们希望将它变成64种颜色，那只需要将原来的颜色除以4(整除)以后再乘以4

###5.5
Mat类中的cols和rows给出了图像的宽和高。而成员函数at (int y, int x)可以用来存取图像元素，但是必须在编译期知道图像的数据类型。需要注意的是，我们一定要确保指定的数据类型要和矩阵中的数据类型相符合，因为at方法本身不会对任何数据类型进行转换。
对于彩色图像，每个像素由三个部分构成：蓝色通道、绿色通道和红色通道(BGR)。因此，对于一个包含彩色图像的Mat，会返回一个由三个8位数组成的向量。OpenCV将此类型的向量定义为Vec3b，即由三个unsigned char组成的向量。这也解释了为什么存取彩色图像像素的代码可以写出如下形式：
image.at<Vec3b>(j,i)[channel]=value;
其中，索引值channel标明了颜色通道号。
另外需要再次提醒大家的是，OpenCV中的彩色图像不是以RGB的顺序存放的，而是BGR，所以程序中的outputlmage.at<Vec3b>(ij)[0]代表的是该点的B分量。同理还有(*it)[0]。

###5.6感兴趣区域：ROI
在图像处理领域，我们常常需要设置感兴趣区域(ROI, region of interest),来专注或者简化工作过程。也就是从图像中选择的一个图像区域，这个区域是图像分析所关注的重点。我们圈定这个区域，以便进行进一步处理。而且，使用ROI指定想读入的目标，可以减少处理时间，增加精度，给图像处理来带不小的便利。
定义ROI区域有两种方法：第一种是使用表示矩形区域的Rect。它指定矩形的左上角坐标(构造函数的前两个参数)和矩形的长宽(构造函数的后两个参数)以定义一个矩形区域。
其中，image为已经载入好的图片。
11定叉一个Mat 类型并给其设定ROI 区域
Mat imageROI;
//方法一
imageROI=image (Rect (500,250, logo.cols, logo,rows))；
另一种定义ROI的方式是指定感兴趣行或列的范围(Range)。 Range是指从起始索引到终止索引(不包括终止索引)的一连段连续序列。cRange可以用来定义Range。如果使用Range来定义ROI，那么前例中定义ROI的代码可以重写为：
11方法二
imageROI=image (Range (250,250+1ogoImage.rows),Range (200,200+logoImage.cols));
下面我们来看一个实例，显示如何利用ROI将一幅图加到另一幅图的指定位置。大家如果需要复制以下函数中的代码直接运行，可以自己建一个基于console的程序，然后把函数体中的内容复制到main函数中，然后找两幅大小合适的图片，加入到工程目录下，并和代码中读取的文件名一致即可。
在下面的代码中，我们通过一个图像掩膜(mask)，直接将插入处的像素设置为logo图像的像素值，这样效果会很逼真。
【ROI_AddImage()函数】
函数名：ROI AddImage ()
描述：利用感兴趣区域ROI实现图像叠加
bool ROI_AddImage ()
//【1】读入图像
Mat srcImagel- Imread("dota_pa.jpg");
Mat logoImage= imread("dota logo.ipg");
if (lareImage1.data)( printf("读取srcImagel错误~！ \n")；returnfalse:
if(!logoImage.data)(printf("读取ogoImage 错误~！\n");returnfalse;
//【2】定义一个Mat 类型并给其设定ROI区域
Mat imageROI=
srcImagel(Rect (200,250,logoImage.cols,logoImage.rows));
//【3】加载掩模(必须是灰度图)
Mat mask= imread("dota_logo.jpg",0);
//【4】将掩膜复制到 ROI
logoImage.copyTo(imageROI,mask);
//【5】显示结果
namedWindow("<1>利用ROI 实现图像叠加示例窗口")；
imshow("利用ROI实现图像叠加示例窗口"，srcImagel)；
return true;
}
用指针访问像素代码如下
//---------------------------------【头文件、命名空间包含部分】--------------------------
//		描述：包含程序所使用的头文件和命名空间
//-----------------------------------------------------------------------------------------------
 #include <opencv2/core/core.hpp>  
 #include <opencv2/highgui/highgui.hpp>  
 #include <iostream>  
using namespace std;  
using namespace cv;  

//-----------------------------------【全局函数声明部分】-----------------------------------
//          描述：全局函数声明
//-----------------------------------------------------------------------------------------------
void colorReduce(Mat& inputImage, Mat& outputImage, int div);  
void ShowHelpText();



//--------------------------------------【main( )函数】---------------------------------------
//          描述：控制台应用程序的入口函数，我们的程序从这里开始执行
//-----------------------------------------------------------------------------------------------
int main( )  
{  
	//【1】创建原始图并显示
	Mat srcImage = imread("1.jpg");  
	imshow("原始图像",srcImage);  

	//【2】按原始图的参数规格来创建创建效果图
	Mat dstImage;
	dstImage.create(srcImage.rows,srcImage.cols,srcImage.type());//效果图的大小、类型与原图片相同 

	ShowHelpText();

	//【3】记录起始时间
	double time0 = static_cast<double>(getTickCount());  

	//【4】调用颜色空间缩减函数
	colorReduce(srcImage,dstImage,32);  

	//【5】计算运行时间并输出
	time0 = ((double)getTickCount() - time0)/getTickFrequency();
	cout<<"\t此方法运行时间为： "<<time0<<"秒"<<endl;  //输出运行时间

	//【6】显示效果图
	imshow("效果图",dstImage);  
	waitKey(0);  
}  


//---------------------------------【colorReduce( )函数】---------------------------------
//          描述：使用【指针访问：C操作符[ ]】方法版的颜色空间缩减函数
//----------------------------------------------------------------------------------------------
void colorReduce(Mat& inputImage, Mat& outputImage, int div)  
{  
	//参数准备
	outputImage = inputImage.clone();  //拷贝实参到临时变量
	int rowNumber = outputImage.rows;  //行数
	int colNumber = outputImage.cols*outputImage.channels();  //列数 x 通道数=每一行元素的个数

	//双重循环，遍历所有的像素值
	for(int i = 0;i < rowNumber;i++)  //行循环
	{  
		uchar* data = outputImage.ptr<uchar>(i);  //获取第i行的首地址
		for(int j = 0;j < colNumber;j++)   //列循环
		{  	
			// ---------【开始处理每个像素】-------------     
			data[j] = data[j]/div*div + div/2;  
			// ----------【处理结束】---------------------
		}  //行处理结束
	}  
}  

![4.png](https://i.loli.net/2020/11/25/WkxbjOV6zFNLQCn.png)

 #include <opencv2/core/core.hpp>  
 #include <opencv2/highgui/highgui.hpp>  
 #include <iostream>  
using namespace std;  
using namespace cv;  

//-----------------------------------【全局函数声明部分】-----------------------------------
//          描述：全局函数声明
//-----------------------------------------------------------------------------------------------
void colorReduce(Mat& inputImage, Mat& outputImage, int div);  
void ShowHelpText();


//--------------------------------------【main( )函数】---------------------------------------
//          描述：控制台应用程序的入口函数，我们的程序从这里开始执行
//-----------------------------------------------------------------------------------------------
int main( )  
{  
	system("color 9F");
	//【1】创建原始图并显示
	Mat srcImage = imread("1.jpg");  
	imshow("原始图像",srcImage);  

	//【2】按原始图的参数规格来创建创建效果图
	Mat dstImage;
	dstImage.create(srcImage.rows,srcImage.cols,srcImage.type());//效果图的大小、类型与原图片相同 

	ShowHelpText();

	//【3】记录起始时间
	double time0 = static_cast<double>(getTickCount());  

	//【4】调用颜色空间缩减函数
	colorReduce(srcImage,dstImage,32);  

	//【5】计算运行时间并输出
	time0 = ((double)getTickCount() - time0)/getTickFrequency();
	cout<<"此方法运行时间为： "<<time0<<"秒"<<endl;  //输出运行时间

	//【6】显示效果图
	imshow("效果图",dstImage);  
	waitKey(0);  
}  


//----------------------------------【colorReduce( )函数】-------------------------------
//          描述：使用【动态地址运算配合at】方法版本的颜色空间缩减函数
//----------------------------------------------------------------------------------------------
void colorReduce(Mat& inputImage, Mat& outputImage, int div)  
{  
	//参数准备
	outputImage = inputImage.clone();  //拷贝实参到临时变量
	int rowNumber = outputImage.rows;  //行数
	int colNumber = outputImage.cols;  //列数

	//存取彩色图像像素
	for(int i = 0;i < rowNumber;i++)  
	{  
		for(int j = 0;j < colNumber;j++)  
		{  	
			// ------------------------【开始处理每个像素】--------------------
			outputImage.at<Vec3b>(i,j)[0] =  outputImage.at<Vec3b>(i,j)[0]/div*div + div/2;  //蓝色通道
			outputImage.at<Vec3b>(i,j)[1] =  outputImage.at<Vec3b>(i,j)[1]/div*div + div/2;  //绿色通道
			outputImage.at<Vec3b>(i,j)[2] =  outputImage.at<Vec3b>(i,j)[2]/div*div + div/2;  //红是通道
			// -------------------------【处理结束】----------------------------
		}  // 行处理结束     
	}  
}  


关于Write_XML的实验
//---------------------------------【头文件、命名空间包含部分】-------------------------------
//		描述：包含程序所使用的头文件和命名空间
//------------------------------------------------------------------------------------------------
 #include "opencv2/opencv.hpp"  
 #include <time.h>  
using namespace cv;  
//-----------------------------------【main( )函数】--------------------------------------------
//	描述：控制台应用程序的入口函数，我们的程序从这里开始
//-----------------------------------------------------------------------------------------------
int main( )  
{  
	//改变console字体颜色
	system("color 5F"); 

	ShowHelpText();

	//初始化
	FileStorage fs("test.yaml", FileStorage::WRITE);  

	//开始文件写入
	fs << "frameCount" << 5;  
	time_t rawtime; time(&rawtime);  
	fs << "calibrationDate" << asctime(localtime(&rawtime));  
	Mat cameraMatrix = (Mat_<double>(3,3) << 1000, 0, 320, 0, 1000, 240, 0, 0, 1);  
	Mat distCoeffs = (Mat_<double>(5,1) << 0.1, 0.01, -0.001, 0, 0);  
	fs << "cameraMatrix" << cameraMatrix << "distCoeffs" << distCoeffs;  
	fs << "features" << "[";  
	for( int i = 0; i < 3; i++ )  
	{  
		int x = rand() % 640;  
		int y = rand() % 480;  
		uchar lbp = rand() % 256;  

		fs << "{:" << "x" << x << "y" << y << "lbp" << "[:";  
		for( int j = 0; j < 8; j++ )  
			fs << ((lbp >> j) & 1);  
		fs << "]" << "}";  
	}  
	fs << "]";  
	fs.release();  

	printf("\n文件读写完毕，请在工程目录下查看生成的文件~");
	getchar();

	return 0;  
}  
结果代码如下
![xml写入.png](https://i.loli.net/2020/11/25/UoA9CFPlXWDEvS4.png)


关于XML和YAML文件的读取的实验
代码如下
//---------------------------------【头文件、命名空间包含部分】-------------------------------
//		描述：包含程序所使用的头文件和命名空间
//------------------------------------------------------------------------------------------------       
 #include "opencv2/opencv.hpp"  
 #include <time.h>  
using namespace cv;  
using namespace std;  
int main( )  
{  
	//改变console字体颜色
	system("color 6F"); 

	ShowHelpText();

	//初始化
	FileStorage fs2("test.yaml", FileStorage::READ);  

	// 第一种方法，对FileNode操作
	int frameCount = (int)fs2["frameCount"];  

	std::string date;  
	// 第二种方法，使用FileNode运算符> > 
	fs2["calibrationDate"] >> date;  

	Mat cameraMatrix2, distCoeffs2;  
	fs2["cameraMatrix"] >> cameraMatrix2;  
	fs2["distCoeffs"] >> distCoeffs2;  

	cout << "frameCount: " << frameCount << endl  
		<< "calibration date: " << date << endl  
		<< "camera matrix: " << cameraMatrix2 << endl  
		<< "distortion coeffs: " << distCoeffs2 << endl;  

	FileNode features = fs2["features"];  
	FileNodeIterator it = features.begin(), it_end = features.end();  
	int idx = 0;  
	std::vector<uchar> lbpval;  

	//使用FileNodeIterator遍历序列
	for( ; it != it_end; ++it, idx++ )  
	{  
		cout << "feature #" << idx << ": ";  
		cout << "x=" << (int)(*it)["x"] << ", y=" << (int)(*it)["y"] << ", lbp: (";  
		// 我们也可以使用使用filenode > > std::vector操作符很容易的读数值阵列
		(*it)["lbp"] >> lbpval;  
		for( int i = 0; i < (int)lbpval.size(); i++ )  
			cout << " " << (int)lbpval[i];  
		cout << ")" << endl;  
	}  
	fs2.release();  

	//程序结束，输出一些帮助文字
	printf("\n文件读取完毕，请输入任意键结束程序~");
	getchar();

	return 0;  
}  
实验结果如下
![xml读取结果.png](https://i.loli.net/2020/11/25/8GFwWgE5uaf9nKq.png)
